{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dowload and clean german Wikipedia dump"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "# regex\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "import bz2\n",
    "import requests\n",
    "\n",
    "# package to read wikipedia dump\n",
    "import mwxml\n",
    "# packages for cleaning the data\n",
    "import html2text\n",
    "import wikitextparser as wtp\n",
    "\n",
    "# packages for multithreading\n",
    "from threading import Thread\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static Variables / Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# static var\n",
    "DUMP_URL = 'https://dumps.wikimedia.org/dewiki/latest/dewiki-latest-pages-articles.xml.bz2'\n",
    "DUMP_FILE_ZIP = './dewiki-latest-pages-articles.xml.bz2'\n",
    "DUMP_FILE_ENTPACKT = './dewiki-latest-pages-articles.xml'\n",
    "EXZELLENT_FOLDER = './exzellent'\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funktionen definieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_save_article(page, revision):\n",
    "    text = revision.text\n",
    "\n",
    "    # entnommen aus: https://github.com/daveshap/PlainTextWikipedia\n",
    "    # Plain Text\n",
    "    text = wtp.parse(text).plain_text()  \n",
    "    # Remove HTML\n",
    "    text = html2text.html2text(text)\n",
    "    # Replace newlines\n",
    "    text = text.replace('\\\\n', ' ') \n",
    "    # Replace excess whitespace\n",
    "    text = re.sub('\\s+', ' ', text)  \n",
    "    # end entnommen aus\n",
    "    \n",
    "    with open(os.path.join(EXZELLENT_FOLDER, str(page.id) + '.txt'), \"x\") as f:\n",
    "        f.write(page.title + \"\\n\" + text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download XML Dump herunterladen und Chunkweise abspeichern\n",
    "\n",
    "Herunterladen des Wikipedia Dumps mit allen deutschsprachigen Artikeln von wikimedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zum Herunterladen der Datei\n",
    "def download_file(url, file_path):\n",
    "    response = requests.get(url, stream=True)\n",
    "    with open(file_path, 'wb') as file:\n",
    "        for chunk in response.iter_content(chunk_size=1024):\n",
    "            if chunk:\n",
    "                file.write(chunk)\n",
    "\n",
    "# Herunterladen des Wikipedia-Artikeldumps\n",
    "download_file(DUMP_URL, DUMP_FILE_ZIP)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XML Dump entpacken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip the xml-dump and save it\n",
    "with open(DUMP_FILE_ENTPACKT, 'wb') as new_file, bz2.BZ2File(DUMP_FILE_ZIP, 'rb') as file:\n",
    "    for data in iter(lambda : file.read(100 * 1024), b''):\n",
    "        new_file.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Wikipedia Dump ###\n",
      "Wikipedia dewiki\n",
      "### Exzelente Aritkel ###\n",
      "Gefundene exzellente Artikel: 2793Anzahl der exzellenten Artikel:  2793\n"
     ]
    }
   ],
   "source": [
    "# pythonhosted.org\n",
    "pattern = r\"\\{\\{Exzellent\\|\"\n",
    "dump = mwxml.Dump.from_file(open(DUMP_FILE_ENTPACKT))\n",
    "\n",
    "print(\"### Wikipedia Dump ###\")\n",
    "print(dump.site_info.name, dump.site_info.dbname)\n",
    "\n",
    "print(\"### Exzelente Aritkel ###\")\n",
    "if not os.path.isdir(EXZELLENT_FOLDER):\n",
    "    os.makedirs(EXZELLENT_FOLDER)\n",
    "excellent_count = 0\n",
    "    \n",
    "# for schleifen entnommen aus: \n",
    "for idx_page, page in enumerate(dump):\n",
    "    for idx_revision, revision in enumerate(page):\n",
    "        if revision.text is not None:\n",
    "            x = re.search(pattern, revision.text)\n",
    "            if x is not None:\n",
    "                # finde the excellent articles\n",
    "                excellent_count += 1\n",
    "                Thread(target=clean_save_article, args=(page, revision)).start()\n",
    "                sys.stdout.write('\\rGefundene exzellente Artikel: ' + str(excellent_count))\n",
    "                sys.stdout.flush()\n",
    "\n",
    "print('')\n",
    "print('Anzahl der exzellenten Artikel: ', str(excellent_count))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
