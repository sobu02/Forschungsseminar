Numerische lineare Algebra numerische lineare Algebra zentrales Teilgebiet numerischen Mathematik Entwicklung Analyse Rechenverfahren Algorithmen Problemstellungen linearen Algebra Lösung linearen Gleichungssystemen Eigenwertproblemen Probleme Ingenieurwissenschaften Ökonometrie Statistik große Rolle Algorithmen numerischen linearen Algebra grob Gruppen direkten Verfahren theoretisch Rechenschritten exakte Lösung Problems iterativen Verfahren exakte Lösung genauer direkten Verfahren endlicher Genauigkeit entstehenden Rundungsfehler Näherungen exakte Lösung Unterscheidung Entwicklung Untersuchung Verfahren Bedeutung praktischen Einsatz große Rolle Historisch ersten systematischen Verfahren Gruppen direkte gaußsche Eliminationsverfahren iterative Gauß-Seidel-Verfahren Carl Friedrich Gauß Beispiele bedeutende Verfahren 20. Jahrhunderts zahlreiche Verbesserungen Weiterentwicklungen Folge Zerlegungsverfahren André-Louis Cholesky QR- Verfahren Eigenwertprobleme John G F. Francis Wera Nikolajewna Kublanowskaja CG-Verfahren Eduard Magnus Hestenes erster Vertreter wichtigen Krylow-Unterraum-Verfahren Einführung Problemstellungen historisch zentraler Anfangspunkt elementaren linearen Algebra lineare Gleichungssysteme Gleichungen Gestalt Unbekannte Koeffizienten gegebene Zahlen gesuchten Werte Gleichungen Koeffizienten Matrix Zahlen Unbekannten x_j Spaltenvektoren \mathbf \mathbf Weise Matrix-Vektor-Darstellung \mathbf linearen Gleichungssystems Vektor Matrix-Vektor-Multiplikation gegebenen Matrix A gegebenen Vektor Teilgebiet Numerik numerische lineare Algebra sogenannte korrekt gestellte Probleme Probleme Lösung Lösung eindeutig Folgenden Matrix A regulär Inverse rechte Seite eindeutig bestimmte Lösung linearen Gleichungssystems formal wichtige Anwendungen lineare Gleichungssysteme Gleichungen Unbekannten Matrix-Vektor-Darstellung A \cdot Fall Matrix A Zeilen Spalten überbestimmten Systeme Allgemeinen Lösung Vektor Differenz Residuum festzulegenden Sinn klein Abstand wichtigsten Fall sogenannten linearen Ausgleichsproblem Methode kleinsten Quadrate Quadratsumme minimal Komponenten Differenzvektors Mithilfe euklidischen Norm \mathbf minimal linearen Gleichungen Eigenwertprobleme weiteres zentrales Thema linearen Algebra Gegeben Matrix A Zeilen Zahlen \lambda Vektoren sodass Gleichung \mathbf \mathbf Eigenvektor A Eigenwert \lambda Problem Eigenwerte Eigenvektoren Matrix gleichbedeutend reguläre Matrix S Diagonalmatrix D D Diagonaleinträge D Eigenwerte A Spalten S zugehörigen Eigenvektoren Probleme Ingenieurwissenschaften Wirtschaftswissenschaften Statistik Gebieten statistischer Methoden große Rolle Lineare Gleichungssysteme Modelle Statik elektrische Netzwerke volkswirtschaftliche Verflechtungen scheinbar unterschiedliche Aufgabenstellungen Stabilitätsuntersuchung dynamischer Systeme Resonanzphänomene Schwingungen Bestimmung PageRanks Hauptkomponentenanalyse Statistik Eigenwertprobleme Lineare Gleichungen Linearisierung Diskretisierung anderer numerischer Verfahren zahlreiche Modelle Naturwissenschaft Technik partielle Differentialgleichungen numerische Lösung Finite-Elemente-Verfahren Systeme Unbekannten Übersichtsartikel Einfachheit halber gegebenen Matrizen Vektoren reell Einträge reelle Zahlen angesprochenen Verfahren direkt komplexe Zahlen Stelle orthogonalen Matrizen komplexes Pendant unitären Matrizen vorteilhaft gegebenes komplexes Problem Betrachtung Imaginärteil reelles Zusatzüberlegungen Eigenwertproblemen nichtsymmetrischen reellen Matrizen nichtreelle Eigenwerte Eigenvektoren Geschichte Anfänge Gauß Jacobi Antike Lösungen konkreter Problemstellungen heutiger Sicht lineare Gleichungssysteme Kapitel Rechenkunst Stand chinesischen Mathematik 1. Jahrhunderts Chr. tabellarische Rechenvorschriften Eliminationsverfahren Matrixdarstellung systematische Untersuchung linearer Gleichungssysteme Ende 17. Jahrhunderts Formulierung allgemeiner Koeffizienten Vorarbeiten Gottfried Wilhelm Leibniz Colin Maclaurin Gabriel Cramer explizite Lösungsformel beliebig Unbekannte Determinanten cramerschen Regel Problem theoretisch vollständig Hinblick Existenz Eindeutigkeit Lösungen praktische Berechnung Formel völlig ungeeignet Rechenaufwand Anzahl Unbekannten astronomisch schnell Cramersche Regel S. erste Verwendung Beschreibung systematischer Rechenverfahren lineare Gleichungen Carl Friedrich Gauß Beginn 19. Jahrhunderts Bestimmung Bahndaten astronomischer Objekte Landesvermessung Triangulation wichtigsten Anwendungsaufgaben mathematischen Praxis Gauß großes Aufsehen Bahn neu entdeckten Kleinplaneten Ceres Beobachtungen genau Ceres Ende Jahres zugehörige überbestimmte Gleichungssystem entdeckte Methode kleinsten Quadrate Berechnung Lösung eingesetzte Eliminationsverfahren Gauß systematisch Rahmen Bahnbestimmung Asteroiden Pallas direkt Quadratsummen.Chabert S. Jacobi erste Iterationsverfahren Lösung linearer Gleichungssysteme Gauß-Seidel-Verfahren Gauß Brief Christian Ludwig Gerling neuen einfachen Verfahren Lösung Schritt Schritt besser Gauß Triangulation Königreichs Hannover Abend Iterationsschritt angenehme Abwechslung einförmigen Aufnahme Messdaten Verfahren anfällig Fehler halb Schlaf lasse.Chabert S. Carl Gustav Jacob Jacobi anderes ähnliches Iterationsverfahren Jacobi-Verfahren Philipp Ludwig Seidel Schüler Jacobis System Unbekannten modifizierte verbesserte Version Methode Verfahren äquivalent Iterationsverfahren Gauß Seidel wusste.Chabert S Jacobi iteratives Verfahren Transformation Matrizen Lösung Eigenwertproblems symmetrische Matrizen Jacobi-Verfahren Vorbereitungsschritt Diagonaleinträge Matrix stärker dominant machen.Golub 20th century S. 20. Jahrhundert Jahr André-Louis Cholesky entwickeltes Verfahren bestimmte lineare Gleichungssysteme Koeffizientenmatrix Produkt zweier einfacherer Matrizen Cholesky-Zerlegung gaußsche Eliminationsverfahren Spezialfall Matrixzerlegungsverfahren Algorithmen Verfahrensgruppe Standardverfahren Lösung mäßig großer Systeme.Chabert S. Ende 1920er Jahre neue Ideen iterativen Lösung Eigenwertproblemen beginnend Vorstellung Potenzmethode Richard Mises Weiterentwicklung inversen Iteration Helmut Wielandt einfachen Vektoriterationsverfahren Eigenvektoren einzelnen Eigenwert werden.Golub 20th century S. vollständige Lösung Eigenwertproblems beliebige Matrizen aufwändig Durchbruch Entwicklung QR-Verfahrens britischen Informatiker John G F. Francis unabhängig russische Mathematikerin Wera Nikolajewna Kublanowskaja Kublanowskaja Arbeit Anfang tiefes Verständnis Konvergenzeigenschaften Methode Francis Implementierungsdetails Verfahren schnell stabil QR-Verfahren Standardverfahren Berechnung Eigenwerte Eigenvektoren großer Matrizen.Golub 20th century S. 47. mini|hochkant|Eduard Lösung linearer Gleichungssysteme großen Matrizen Diskretisierung partiellen Differentialgleichungen schwierig Matrizen relativ Einträge ungleich null entscheidender Bedeutung numerisches Verfahren Eigenschaft neuer Ansatz Startpunkt zahlreicher Weiterentwicklungen Eduard Magnus Hestenes entwickelte CG-Verfahren lineare Gleichungssystem Spezialfall Matrix symmetrisch zusätzlich positiv definit äquivalentes Optimierungsproblem fruchtbarer anderer Zugang CG-Verfahren gleichzeitig Cornelius Lanczos CG- Verfahren berechneten Näherungen aufsteigenden Kette Unterräumen Krylow-Räumen.Saad linear 20th century S. Trotz Entdeckung Zusammenhänge relativ konkrete Verallgemeinerungen CG-Verfahrens Roger Fletcher veröffentlichte BiCG-Verfahren theoretisch beliebige Matrizen anwendbar Praxis Fällen instabil erschienene MINRES-Verfahren Krylow-Unterraum-Verfahren Matrix symmetrisch positiv definit linear 20th century S. Folgezeit zahlreiche Weiterentwicklungen Stabilisierungsversuche BiCG-Verfahren Beispiel weit verbreitetes Krylow-Unterraum-Verfahren beliebige lineare Gleichungssysteme Verallgemeinerung MINRES-Verfahrens Yousef Saad Martin H. Schultz vorgestellte GMRES-Verfahren Weitere Verfahren Synthesen Ideen BiCG-Gruppe GMRES QMR-Verfahren Roland W. Freund Noel M. Nachtigal TFQMR-Verfahren Freund linear 20th century S Anfang Krylow- Unterraum-Verfahren Berechnung Eigenwerten Ausgangspunkte Verfahren Lanczos Verfahren Walter Edwin Arnoldi 1951.Golub 20th century S. Grundprinzipien Ausnutzung Strukturen mini|Besetzungsstruktur dünnbesetzten Matrix Finite-Elemente-Methode kleinen schwarzen Quadrate Matrixeinträge ungleich null Modelle Fragestellungen Wissenschaft Technik Probleme linearen Algebra Millionen Gleichungen Einträge Matrix Million Zeilen Spalten double-precision-Format Terabyte Speicherplatz Bereitstellung Daten Problems Lösung Herausforderung spezielle Struktur wichtige Anwendungen Diskretisierung partieller Differentialgleichungen Finite-Elemente-Methode Gleichungen einzelnen Gleichung relativ Unbekannte zugehörige Matrix Zeile Einträge ungleich null Matrix zahlreiche Methoden Matrizen effizient Struktur Verfahren Matrizen Matrix-Vektor-Produkten dünnbesetzte Probleme gut Multiplikationen Additionen explizit Algorithmen Matrix schwierig Dünnbesetztheit Allgemeinen geht.Demmel Applied Numerical Linear Algebra S Allgemein Besetzungsstruktur Anzahl Position Matrixeinträge ungleich null großen Einfluss theoretischen numerischen Eigenschaften Problems Extremfall Diagonalmatrizen Matrizen Hauptdiagonale Einträge ungleich null deutlich lineares Gleichungssystem Diagonalmatrix einfach Einträge rechten Seite Diagonalelemente Divisionen lineare Ausgleichsprobleme Eigenwertprobleme Diagonalmatrizen trivial Eigenwerte Diagonalmatrix Diagonalelemente zugehörigen Eigenvektoren Standardbasisvektoren \mathbf weiterer wichtiger Spezialfall Dreiecksmatrizen Einträge Hauptdiagonale null Gleichungssysteme Matrizen Rückwärtseinsetzen Reihe Eigenwerte Dreiecksmatrizen Einträge Hauptdiagonale zugehörige Eigenvektoren Rückwärtseinsetzen weiterer häufiger Spezialfall dünnbesetzter Matrizen Bandmatrizen Hauptdiagonale benachbarte Nebendiagonalen Einträgen ungleich null Abschwächung oberen Dreiecksmatrizen oberen Hessenbergmatrizen Nebendiagonale Hauptdiagonale Eigenwertprobleme relativ geringem Aufwand äquivalente Probleme Tridiagonalmatrizen Besetzungsstruktur andere Matrixeigenschaften Entwicklung Analyse numerischer Verfahren wichtige Rolle Anwendungen Probleme symmetrischen Matrizen Eigenwertprobleme deutlich einfacher gegebene Matrix symmetrisch Golub Van Loan Matrix Computations S. linearen Gleichungssystemen Fall Lösungsaufwand Allgemeinen Hälfte Weitere Beispiele Typen Matrizen spezialisierte Algorithmen Vandermonde-Matrizen Toeplitz-Matrizen zirkulanten Matrizen.Golub Van Loan Matrix Computations S. S. S. Fehleranalyse Matrixnormen Maße Größe Vektors Mathematik unterschiedliche Vektornormen bekanntesten verbreitetsten euklidische Norm Wurzel Summe Quadrate Vektorkomponenten bekannten geometrischen Veranschaulichung Vektoren Pfeile dreidimensionalen Raum Pfeillänge untersuchter Fragestellung andere Vektornormen Maximumsnorm 1-Norm \|\mathbf geeigneter \tilde\mathbf \tilde\mathbf Näherung mithilfe Vektornorm Genauigkeit Näherung Norm Differenzvektors normweiser absoluter Fehler Betrachtet absoluten Fehler Verhältnis Norm exakten \mathbf normweisen relativen Fehler relative Fehler Skalierung \tilde\mathbf Standardmaß Unterschied Vektoren Fehler Größe Matrizen Normen Matrixnormen Wahl Matrixnorm wesentlich verwendeten Vektornorm Ungleichung gegebene Vektornorm kleinste Zahl L sodass L sogenannte natürliche Matrixnorm Vektornorm induzierte natürliche Matrixnorm euklidische Norm Spektralnorm Maximumsnorm Zeilensummennorm 1-Norm Spaltensummennorm Analog Vektoren mithilfe Matrixnorm relative Fehler Näherung Matrix A Matrix \tilde A Kondition Stabilität mini|Zweidimensionale Veranschaulichung Multiplikation Matrix A Einheitskreis blau Ellipse grün Konditionszahl A Verhältnis großer kleiner Halbachse Stärke Verzerrung Problemen Praxis gegebene Größen Fehlern Datenfehlern Beispiel linearen Gleichungssystem gegebene rechte Seite Messung Messabweichung theoretisch beliebig genau bekannten Größen Rundungsfehler Darstellung Computer Gleitkommazahlen exakten Systems Wirklichkeit System A \tilde\mathbf gestörten rechten Seite \tilde\mathbf b dementsprechend falschen Lösung grundlegende Frage stark Störungen gegebenen Größen Störungen gesuchten Größen relative Fehler Lösung wesentlich größer relativen Fehler Eingangsgrößen gut konditionierten anderenfalls schlecht konditionierten Problem Beispiel linearer Gleichungssysteme Abschätzung Problem konditioniert Produkt Norm Koeffizientenmatrix Norm Inversen klein wichtige Kenngröße Konditionszahl Matrix A \kappa A realen Problemen rechte Seite Matrix A ähnliche kompliziertere Abschätzung \kappa A wesentliche Kennzahl Bestimmung Kondition Problems kleinen Datenfehlern Definition Konditionszahl quadratische Matrizen wesentliche Rolle Analyse linearer Ausgleichsprobleme gut Problem konditioniert linearen Gleichungssystemen Konditionszahl Koeffizientenmatrix A rechten Seite genauer Winkel Vektoren b.Trefethen Bau Numerical Linear Algebra S. Satz Bauer-Fike Kondition Eigenwertproblems Konditionszahlen Zahl \kappa A Störungen Eigenwerte \kappa S Konditionszahl Matrix S A Kondition Eigenschaft lösenden Problems Stabilität Eigenschaft verwendeten Verfahrens numerischer Algorithmus exakt gedachten Eingangsdaten Allgemeinen exakte Lösung Problems Beispiel iteratives Verfahren wahre Lösung genauer Schritten erreichten Näherungslösung direkten Verfahren theoretisch Rechenschritten exakte Lösung Umsetzung Computer Rechenoperation Rundungsfehlern numerischen Mathematik unterschiedliche Stabilitätsbegriffe Vorwärtsstabilität Rückwärtsstabilität allgemein Eingabegröße Problems exakte Lösung Wert Funktion Eingabegröße exakt Berechnung Algorithmus anderes falsches Ergebnis \tilde \operatorname Wert anderen falschen Funktion \operatorname Algorithmus vorwärtsstabil \tilde wesentlich stärker Fehler Eingangsgröße Kondition Problems formalen Definition Begriffs naheliegendes relativ anschauliches Maß Stabilität komplizierten Algorithmen schwierig Vorwärtsstabilität Allgemeinen Idee James H. Wilkinson sogenannte Rückwärtsanalyse \tilde bestimmt \operatorname Verfahren falsche Wert richtiger Wert anderen Wert Eingabegröße Algorithmus rückwärtsstabil \tilde wesentlich stärker Fehler Eingangsgröße rückwärtsstabiler Algorithmus vorwärtsstabil Orthogonalität orthogonale Matrizen lineare Algebra enger Zusammenhang Matrizen Basen Vektorraums linear unabhängige Vektoren \mathbf gegeben Basis Raums andere Vektor eindeutig Linearkombination Basisvektoren Basiswechsel Multiplikation gegebener Vektoren Matrizen Transformationsmatrix wichtigen Spezialfall Orthonormalbasen Basisvektoren paarweise orthogonal senkrecht euklidische Länge normiert Standardbasis \mathbf \mathbf dreidimensionalen Raum Basisvektoren Matrix \mathbf Fall Orthonormalbasis sogenannte orthogonale Matrix Orthonormalbasen orthogonale Matrizen zahlreiche bemerkenswerte Eigenschaften wichtigsten Verfahren modernen numerischen linearen Algebra basieren.Trefethen Bau Numerical Linear Algebra S. Tatsache orthogonalen Matrix Q Spalten Orthonormalbasis Matrixschreibweise Gleichung Q^T transponierte Matrix Einheitsmatrix orthogonale Matrix regulär Inverse Transponierten Lösung linearen Gleichungssystems einfach \mathbf andere grundlegende Eigenschaft Multiplikation Vektors orthogonalen Matrix euklidische Norm unverändert Spektralnorm Konditionszahl \kappa Q^ orthogonale Matrix Multiplikationen orthogonalen Matrizen Vergrößerung relativen Fehlers Orthogonale Matrizen wichtige Rolle Theorie numerischen Behandlung Eigenwertproblemen einfachsten Version Spektralsatzes symmetrische Matrizen orthogonal Matrix A orthogonale Matrix Q Diagonalmatrix D Diagonale D Eigenwerte A Spalten Q Orthonormalbasis Eigenvektoren erwähnten Satz Bauer-Fike Eigenwertproblem symmetrische Matrizen konditioniert.Demmel Applied Numerical Linear Algebra S. sogenannten schurschen Normalform Verallgemeinerung orthogonalen Transformation nichtsymmetrische Matrizen.Demmel Applied Numerical Linear Algebra S mini|Eine Multiplikation Householder-Matrix gegebenen Vektor geeigneter Wahl Spiegelebene spezielle leicht handhabbare Arten orthogonaler Matrizen zahllosen konkreten Verfahren numerischen linearen Algebra Einsatz Householder-Matrizen Givens-Rotationen Gestalt \in Geometrisch Spiegelungen n-dimensionalen Raums -dimensionalen Hyperebene Nullpunkt orthogonal \mathbf wesentliche Eigenschaft folgende gegebenen leicht sodass zugehörige Householder-Matrix Vektor Vielfaches \mathbf Einträge ersten Weise geeignete Householder-Transformationen Spalte Spalte Matrix A Einträge A Hauptdiagonale Givens-Rotationen spezielle Drehungen zweidimensionale Ebene anderen Dimensionen fest Transformation Givens-Rotation Einträge geeignete Wahl Drehwinkels Einträge Householder-Transformationen Matrizen ganze Teilspalten Givens-Rotationen gezielt einzelne Matrixeinträge Householder-Transformationen Givens-Rotationen gegebene Matrix A obere Dreiecksmatrix QR- Zerlegung A orthogonale Matrix obere Dreiecksmatrix QR-Zerlegung wichtiges vielseitiges Werkzeug zahlreichen Verfahren Bereichen numerischen linearen Algebra Einsatz kommt.Higham S. Ähnlichkeitstransformationen linearen Algebra Untersuchung Eigenwertproblems A \mathbf Matrix A Zeilen charakteristische \lambda \det Polynom Grad Eigenwerte A Nullstellen \chi_A Fundamentalsatz Algebra direkt A genau Eigenwerte Vielfachheit Eigenwerte reellen Matrizen komplexe Zahlen A reelle symmetrische Matrix Eigenwerte reell charakteristische Polynom große theoretische Bedeutung Eigenwertproblem numerischen Berechnung Problem gegebenen Koeffizienten Nullstellen zugehörigen Polynoms Allgemeinen schlecht konditioniert Kleine Störungen Rundungsfehler Koeffizienten Polynoms starken Verschiebung Nullstellen gut konditioniertes Problem Berechnung Eigenwerte mathematisch äquivalentes schlecht konditioniertes Problem Berechnung Nullstellen charakteristischen Polynoms numerische Verfahren Berechnung Eigenwerten Eigenvektoren anderen Grundidee Ähnlichkeitstransformationen quadratische Matrizen ähnlich reguläre Matrix S ähnliche Matrizen gleichen Eigenwerte Ähnlichkeitstransformation Matrix A Matrix B gesuchten Eigenwerte zugehörigen Eigenvektoren leicht Eigenvektor B Eigenvektor A gleichen Eigenwert Grundideen zahlreichen Algorithmen Einsatz Matrix A Ähnlichkeitstransformation Matrix Eigenwertproblem effizienter Folge Ähnlichkeitstransformationen Matrix Dreiecksmatrix genannten Gründen Transformationsmatrizen S orthogonale Matrizen verwendet.Börm Mehl Problems S Verfahren Verfahrensklassen klassische Eliminationsverfahren Gauß Lösung linearer Gleichungssysteme Ausgangspunkt Vergleichsmaßstab weiterentwickelte Verfahren einfaches zuverlässiges Verfahren Modifikation LR- Zerlegung große gut konditionierte Systeme Praxis Verfahren systematisch Variablen gegebenen Gleichungen geeignete Vielfache Gleichung anderen Gleichung System Stufenform Reihe Numerische Überlegungen Spiel Stabilität Verfahrens Matrix A Element Spalte Quotienten Zeile i-Zeile geeignete Zeilenvertauschungen reguläre Matrix A klein Vergleich großer Betrag nachfolgenden Schritten Gefahr Stellenauslöschungen Subtraktionen großer Zahlen Verfahren instabil wichtig Zeilenvertauschungen sogenannte Pivotisierung Beträge klein Faktorisierungsverfahren wichtigsten direkten Verfahren Lösung linearer Gleichungssysteme Faktorisierungsverfahren Grundidee \mathbf Produkt Matrizen allgemein A C. lineare Gleichungssystem BC Schritten Lösung \mathbf y Systems y anschließend Lösung Systems y A y Lösung ursprünglichen Problems ersten Blick Aufgabe lineares Gleichungssystem Aufgabe lineare Gleichungssysteme Idee Faktoren Teilsysteme wesentlich einfacher Ausgangssystem offensichtlicher Vorteil Verfahrensklasse Fall lineare Gleichungssysteme Koeffizientenmatrix A unterschiedlichen rechten Seiten Faktorisierung A Allgemeinen aufwändigste Verfahrensschritt gaußsche Eliminationsverfahren Faktorisierungsverfahren Koeffizienten Matrix Zeilenvertauschungen unteren Dreiecksmatrix L oberen Dreiecksmatrix R Zusätzlich L unipotent Einträge Hauptdiagonale L Wie Allgemeinen Gauß-Elimination Zeilen A formal Hilfe Permutationsmatrix P A zeilenpermutierte Matrix PA Grundprinzip Faktorisierungsverfahren Lösung Dreiecksmatrizen L R zugehörige Permutation nächsten Schritt L \mathbf y zeilenpermutierten rechten Seite Vorwärtseinsetzen R y Rückwärtseinsetzen LR-Zerlegung gaußsche Eliminationsverfahren geeigneter Pivotisierung stabil praktischen Anwendungsaufgaben große Fehlerverstärkung pathologische Beispiele Verfahrensfehler exponentiell Anzahl Unbekannten anwachsen.Demmel Applied Numerical Linear Algebra S. Cholesky-Zerlegung Cholesky-Zerlegung LR-Zerlegung Faktorisierung Matrix A Dreiecksmatrizen Anwendungen auftretenden Fall A symmetrisch positiv definit A^T positive Eigenwerte Voraussetzungen untere Dreiecksmatrix L A allgemeiner Ansatz Matrixeinträge L explizites Verfahren spaltenweise zeilenweise Cholesky-Verfahren Ausnutzung Symmetrie A Rechenaufwand LR-Zerlegung Hälfte Symmetrische positiv definite Koeffizientenmatrizen klassisch Formulierung sogenannten Normalgleichungen Lösung linearer Ausgleichsprobleme Problem äquivalent lineare Gleichungssystem Koeffizientenmatrix A^T A Normalgleichungen symmetrisch Spalten A linear unabhängig positiv definit Cholesky-Verfahren Vorgehen gut konditionierte Probleme Unbekannten Allgemeinen System Normalgleichungen deutlich schlechter konditioniert ursprünglich gegebene lineare Ausgleichsproblem besser Umweg Normalgleichungen direkt QR-Zerlegung A lineare Gleichungssystem Berechnung QR-Zerlegung direkt allgemeinen Prinzip Faktorisierungsverfahren R y \mathbf y Rückwärtseinsetzen guten Kondition orthogonaler Matrizen möglichen Instabilitäten LR-Zerlegung ein.Demmel Applied Numerical Linear Algebra S. Rechenaufwand Allgemeinen doppelt groß sodass Umständen Abwägung Verfahren muss.Meister Numerik linearer Gleichungssysteme S. QR- Zerlegung gängige Verfahren Lösung großer gut konditionierter linearer Ausgleichsprobleme Problem \|A Q^T orthogonal euklidische Norm Q^T letzte Ausdruck Rückwärtseinsetzen ersten Zeilen Splitting-Verfahren völlig andere Idee A \mathbf neue Näherungen gesuchte Lösung Fall Konvergenz Folge \mathbf \mathbf \mathbf \dotsc Iteration geeigneten Anzahl Schritten ausreichend genauen Näherung einfachsten wichtigsten Verfahren Art Iteration Gestalt geeigneten Matrix M geeigneten Vektor \mathbf c. Verfahren genau Eigenwerte M Betrag echt kleiner Fall Iterierten Lösung Gleichung Fixpunkt Iterationsfunktion F \mathbf y M \mathbf y \mathbf c. systematisches Vorgehen Suche geeigneten Algorithmen Gestalt Idee Splitting-Verfahren Matrix A Summe leicht invertierenden Matrix B Rest Umstellen A Fixpunktgleichung M Iterationsverfahren Gestalt Falle Konvergenz Lösung Konvergenzgeschwindigkeit größer kleiner betragsgrößte Eigenwert Iterationsmatrix M beliebige Matrixnormen M abschätzen.Meister Numerik linearer Gleichungssysteme S klassische Beispiele Splitting-Verfahren Jacobi-Verfahren B Diagonalmatrix Hauptdiagonale A Gauß-Seidel-Verfahren unteren Dreiecksanteil A Konvergenzbeschleunigung Fixpunktverfahren Idee Relaxation Iteration Form Korrektur Schritt geeignet gewählten Relaxationsparameter \omega \omega Numerik linearer Gleichungssysteme S. Beispiel Weise Gauß-Seidel-Verfahren SOR-Verfahren.Meister Numerik linearer Gleichungssysteme S. Jacobi-Verfahren Eigenwertberechnung einfaches zuverlässiges iteratives Verfahren Lösung Eigenwertproblems symmetrische Matrizen Jacobi-Verfahren.Börm Mehl Problems S. sukzessive Ähnlichkeitstransformationen Givens-Rotationen Folge symmetrischen Matrizen ähnlich gegebenen symmetrischen Matrix A Diagonalmatrix D Verfahren geeigneten Anzahl Schritten Diagonaleinträgen D Näherungen gesuchten Eigenwerte A Schritt Givens-Rotation Zusammenhang Jacobi-Rotation Eintrag Matrixposition j symmetrisch liegende j Transformation ganze Zeile ganze Spalte Matrix Schritt erzeugten Nullen Allgemeinen folgenden Schritten geeigneter Wahl Positionen Jacobi-Rotationen Nichtdiagonalelemente klassische Jacobi-Verfahren Iterationsschritt Position j Nichtdiagonalelement größten Absolutbetrag Handrechnung Position schnell Umsetzung Computerprogramm Aufwand Suche Vergleich übrigen Rechenoperationen erheblich zyklische Jacobi-Verfahren Positionen fest gewählten Reihenfolge zyklisch spaltenweise.Börm Mehl Problems S. klassische zyklische Jacobi-Verfahren Vergleich moderneren Algorithmen Konvergenz relativ langsam dünnbesetzte Matrizen Jacobi-Verfahren geeignet Laufe Iteration Matrix Nichtnulleinträgen wird.Demmel Applied Numerical Linear Algebra S einfache Ausgangsidee Berechnung Eigenvektoren Matrix A Potenzmethode Startvektor iterativ A oder Matrixpotenz geometrische Anschauung Vektor A Schritt stärksten Richtung Eigenvektors größten Eigenwert einfachen Form Vektoriteration Praxis ungeeignet Allgemeinen Einträge schnell klein groß Vektor Schritt zusätzlich Multiplikation A Vektornorm normiert gewissen Voraussetzungen Lage Eigenwerte Verfahren skalaren Vorfaktor tatsächlich Eigenvektor betragsgrößten Eigenwert Idee formal inverse Matrix Eigenvektor betragskleinsten Eigenwert A Inverse Schritt lineare Gleichungssystem weitere Verallgemeinerung Idee sogenannten Shiftparameters Eigenvektor A nächsten \sigma liegenden Eigenwert Eigenvektor betragskleinsten Eigenwert Matrix zugehörigen Iteration \mathbf Normierung Schritt Verfahren inversen Vektoriteration Vektoriterationsverfahren bestimmten Eigenvektor A zugehörige Eigenwert mithilfe Rayleigh-Quotienten offenbar geeignet häufig bestimmten Anwendungsfällen größte kleinste allgemeiner einzelner Eigenwert Eigenvektor QR-Verfahren wichtigste Algorithmus Berechnung Eigenwerte Eigenvektoren großen vollbesetzten Matrizen A.Börm Mehl Problems S. Iterationsverfahren Schritt QR-Zerlegung wiederholte Ähnlichkeitstransformationen Matrixfolge schnell obere Dreiecksmatrix Startend Ausgangsmatrix Grundidee Schritt Matrix QR-zerlegt A_ anschließend Faktoren umgekehrter Reihenfolge R_k Q_k neue Näherungsmatrix R_k Umformung tatsächlich Ähnlichkeitstransformation orthogonalen Matrix genauere Analyse enger Zusammenhang Potenzmethode QR-Iteration Potenzmethode simultan Vektoren Orthonormalbasis QR-Zerlegung Schritt Vektoren Laufe Iteration numerisch stabil Unterraumiteration Darstellung Beweis Verfahren geringen Voraussetzungen A obere Dreiecksmatrix konvergiert.Trefethen Bau Numerical Linear Algebra S einfachen Form QR-Verfahren Gründen Praxis Rechenaufwand QR- Zerlegung Schritt groß anderen Konvergenz Allgemeinen langsam Schritte gewünschte Genauigkeit ersten Punkt Vorbereitungsschritt Matrix A Ähnlichkeitstransformationen Hessenberg-Gestalt Transformationen geeigneten Householder-Matrizen Hessenberg-Matrix Nichtnulleinträge Hauptdiagonale schnell entsprechenden Givens-Rotationen QR-zerlegen leicht Schritt QR-Verfahrens Symmetrie Hessenberg-Gestalt symmetrische Hessenberg-Matrix Tridiagonalmatrix Verfahren symmetrischen Fall erheblich Konvergenzgeschwindigkeit ähnlich inversen Vektoriteration deutlich Schritt Matrix A_k Matrix A_k geschickt gewählten Shiftparameter \sigma_k Wahl \sigma_k Wert Näherung Eigenwert A verschiedene sogenannte Shiftstrategien.Trefethen Bau Numerical Linear Algebra S Variante QR-Verfahrens sogenannte Singulärwertzerlegung Matrix werden.Demmel Applied Numerical Linear Algebra S Verallgemeinerung Diagonalisierung beliebige quadratische Anwendungen Bildkompression direkt Mithilfe Singulärwertzerlegung große schlecht konditionierte lineare Ausgleichsprobleme werden.Demmel Applied Numerical Linear Algebra S Krylow-Unterraum-Verfahren Die Verfahren zahlreichen Varianten Spezialisierungen wichtigste Verfahrensgruppe Lösung linearen Gleichungssystemen Eigenwertproblemen gegebene Matrix A groß dünnbesetzt historisch erste Algorithmus Gruppe Verfahren konjugierten Gradienten kurz CG-Verfahren Lösung linearer Gleichungssysteme symmetrischen positiv definiten Koeffizientenmatrizen fruchtbare Zusammenhang CG-Verfahrens Krylow-Unterräumen später Grundidee Gleichungssystems äquivalentes Optimierungsproblem A symmetrisch positiv definit Lösung eindeutig bestimmte Minimalstelle Funktion mini|hochkant=0.8|Im zweidimensionalen Fall Höhenlinien minimierenden Funktion Ellipsen Richtung steilsten Abstieg Zickzackkurs grün CG-Verfahren konjugierte Richtungen Schritten genau Minimum rot grundsätzlich numerischen Verfahren Lösung Optimierungsproblemen lineare Gleichungssystem Verfügung sogenannten Abstiegsverfahren iterative Verfahren ausgehend aktuellen Näherung Schritt geeigneten Suchrichtung eindimensionale Optimierungsproblem Suche sodass E minimal gefundene Stelle neue Näherung nächsten Schritt naheliegende Wahl Suchrichtung Richtung steilsten Abstiegs Gradientenverfahren Bestimmung Minimalstelle berechneten Näherungen Allgemeinen langsam wahren Lösung annähern.Meister Numerik linearer Gleichungssysteme S. Wesentlich besser Suchrichtungen spezielle Gestalt minimierenden Funktion E Niveaumengen E -dimensionale Ellipsoide anschaulichen zweidimensionalen Fall Ellipsen günstig Suchrichtungen konjugiert Anschauungsfall konjugierten Durchmessern Richtungen konjugiert \mathbf CG- Verfahren erste Suchrichtung Richtung steilsten Abstiegs folgenden Suchrichtungen Abstiegen wahre Lösung ausreichend genaue Näherungslösung deutlich Schritten Verfahren vorzeitig CG-Verfahren Verfahren Rechenschritten CG-Verfahrens Matrix A Form Matrix-Vektor-Produkten großer Vorteil Vereinfachung Beschränkung Allgemeinheit Startvektor \mathbf Nullvektor genauere Analyse Näherung Linearkombination Vektoren A^2 wiederholten Multiplikationen rechten Seite A Krylow-Unterraum A^2 Eigenschaft Kennzeichen Krylow-Unterraum-Verfahren iterativ Näherungen zusätzlich Residuum festzulegenden Sinne klein CG-Verfahren Bedingung naheliegend spezielle Struktur Problems gut gewichteten Vektornorm Schritt minimal.Demmel Applied Numerical Linear Algebra S. Nachteil A tatsächlich symmetrisch positiv definit anderenfalls Norm Allgemeinen Zusatzbedingungen Krylow-Unterraum-Verfahren Wahl sogenannte Projektionsbedingung Residuum Vektoren k-dimensionalen Unterraum Symbolen \mathcal L_k Krylow-Unterräume einfachsten Fall Verfahren Beispiel K_k.Trefethen Bau Numerical Linear Algebra S konkrete Berechnung Näherungen Orthonormalbasen beteiligten Krylow-Unterräume bekannte Gram-Schmidt-Verfahren Orthonormalisierung Standardform numerisch instabil kleinen Modifikation stabilisieren.Trefethen Bau Numerical Linear Algebra S Weitere Krylow-Unterraum-Verfahren genannten Grundideen zahlreiche Variationen Anpassungen Verbesserungen Verfahrensklasse exemplarisch direkte Verallgemeinerung CG- Verfahrens BiCG-Verfahren Einschränkung symmetrische Matrizen zusätzlich A gebildeten Krylow- Unterräumen transponierten Matrix A^T gehörigen Optimierung zusätzlichen Multiplikationen A^T CGS-Verfahren Verfahrenstypen praktischen Fällen instabil Grundlage verschiedene Stabilisierungsversuche Gruppe BiCGSTAB-Verfahren Wichtige Allgemeinen stabile Verfahren GMRES Spezialisierung symmetrische Matrizen MINRES direkt Residuen Krylow-Unterraum minimal Weitere Verbesserungen Grundprinzips Numerik linearer Gleichungssysteme S. S Krylow-Unterraum-Verfahren große dünnbesetzte lineare Gleichungssysteme Lösung weiterer Grund große Bedeutung modernen numerischen linearen Algebra Eigenwertproblemen \mathbf \mathbf Definition Eigenvektor Näherungen zugehörige \lambda_k \mathbf Vorgehen k-dimensionales Eigenwertproblem kleine k leicht Näherungen Eigenwerte A liefert.Börm Mehl Problems S zugehörige Grundalgorithmus Arnoldi- Verfahren Eigenwertproblemen symmetrische Matrizen deutliche Vereinfachungen Lanczos- Verfahren.Börm Mehl Problems S Literatur Lehrbücher Geschichte Weblinks Kategorie Teilgebiet Mathematik